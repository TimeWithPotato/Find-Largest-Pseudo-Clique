{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896479e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "803ce889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_folder = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491/Backup_synth_graphs/synth-graphs\")\n",
    "graph_folder = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491/Backup_real_graphs/real-graphs\")\n",
    "graph_files = [\n",
    "# \"scale_free_graph_m_21.grh\",\n",
    "# \"scale_free_graph_m_22.grh\",\n",
    "# \"scale_free_graph_m_23.grh\",\n",
    "# \"scale_free_graph_m_24.grh\",\n",
    "# \"scale_free_graph_m_25_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_26_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_26.grh\",\n",
    "# \"scale_free_graph_m_27_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_27.grh\",\n",
    "# \"scale_free_graph_m_28_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_28.grh\",\n",
    "# \"scale_free_graph_m_29_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_29.grh\",\n",
    "# \"scale_free_graph_m_30_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_31_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_32_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_33_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_34_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_35_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_36_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_36.grh\",\n",
    "# \"scale_free_graph_m_37_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_37.grh\",\n",
    "# \"scale_free_graph_m_38_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_38.grh\",\n",
    "# \"scale_free_graph_m_39_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_39.grh\",\n",
    "# \"scale_free_graph_m_40_2nd_time.grh\",\n",
    "# \"scale_free_graph_m_40_3_n_280700_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_40_4_n_363858_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_40_5_n_334219_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_40.grh\",\n",
    "# \"scale_free_graph_m_41_2_n_353022_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_41_3_n_419166_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_41_4_n_433039_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_41_5_n_468780_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_1_n_422475_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_2_n_493128_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_3_n_300906_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_4_n_397965_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_5_n_462328_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_43_1_n_438407_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_43_2_n_428694_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_43_3_n_433925_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_43_4_n_275433_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_43_5_n_317140_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_44_1_n_349663_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_44_2_n_402371_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_44_3_n_201961_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_44_4_n_211853_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_44_5_n_287699_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_45_1_n_279611_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_45_2_n_496705_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_45_5_n_365395_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_38_1_n_366445_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_38_2_n_303099_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_38_3_n_221832_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_38_4_n_440250_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_38_5_n_385252_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_39_1_n_378512_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_39_2_n_354877_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_39_3_n_423427_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_39_4_n_444988_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_39_5_n_481123_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_40_1_n_452586_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_40_2_n_419255_3rd_time.grh\",\n",
    "# \"small_world_graph_m_25_2nd_time.grh\",\n",
    "# \"small_world_graph_m_26_2nd_time.grh\",\n",
    "# \"small_world_graph_m_27_2nd_time.grh\",\n",
    "# \"small_world_graph_m_28_2nd_time.grh\",\n",
    "# \"small_world_graph_m_29_2nd_time.grh\",\n",
    "# \"small_world_graph_m_30_2nd_time.grh\",\n",
    "# \"small_world_graph_m_30.grh\",\n",
    "# \"small_world_graph_m_31_2nd_time.grh\",\n",
    "# \"small_world_graph_m_31.grh\",\n",
    "# \"small_world_graph_m_32_2nd_time.grh\",\n",
    "# \"small_world_graph_m_32.grh\",\n",
    "# \"small_world_graph_m_33_2nd_time.grh\",\n",
    "# \"small_world_graph_m_33.grh\",\n",
    "# \"small_world_graph_m_34_2nd_time.grh\",\n",
    "# \"small_world_graph_m_34.grh\",\n",
    "# \"small_world_graph_m_35_2nd_time.grh\",\n",
    "# \"small_world_graph_m_35.grh\",\n",
    "# \"small_world_graph_m_36_2nd_time.grh\",\n",
    "# \"small_world_graph_m_36.grh\",\n",
    "# \"small_world_graph_m_37_2nd_time.grh\",\n",
    "# \"small_world_graph_m_37.grh\",\n",
    "# \"small_world_graph_m_38_2nd_time.grh\",\n",
    "# \"small_world_graph_m_38.grh\",\n",
    "# \"small_world_graph_m_39_2nd_time.grh\",\n",
    "# \"small_world_graph_m_39.grh\",\n",
    "# \"small_world_graph_m_40_2nd_time.grh\",\n",
    "# \"small_world_graph_m_40.grh\",\n",
    "# \"small_world_graph_m_42_1_p_0.32_n_298510_3rd_time.grh\",\n",
    "# \"small_world_graph_m_42_2_p_0.49_n_278148_3rd_time.grh\",\n",
    "# \"small_world_graph_m_42_3_p_0.54_n_376880_3rd_time.grh\",\n",
    "# \"small_world_graph_m_42_4_p_0.41_n_226396_3rd_time.grh\",\n",
    "# \"small_world_graph_m_42_5_p_0.56_n_267079_3rd_time.grh\",\n",
    "# \"small_world_graph_m_43_1_p_0.32_n_254069_3rd_time.grh\",\n",
    "# \"small_world_graph_m_43_2_p_0.47_n_300101_3rd_time.grh\",\n",
    "# \"small_world_graph_m_43_3_p_0.51_n_239872_3rd_time.grh\",\n",
    "# \"small_world_graph_m_43_4_p_0.51_n_239424_3rd_time.grh\",\n",
    "# \"small_world_graph_m_43_5_p_0.42_n_486968_3rd_time.grh\",\n",
    "# \"small_world_graph_m_44_1_p_0.57_n_374973_3rd_time.grh\",\n",
    "# \"small_world_graph_m_44_2_p_0.5_n_457813_3rd_time.grh\",\n",
    "# \"small_world_graph_m_44_3_p_0.52_n_326786_3rd_time.grh\",\n",
    "# \"small_world_graph_m_44_4_p_0.37_n_362625_3rd_time.grh\",\n",
    "# \"small_world_graph_m_44_5_p_0.47_n_358543_3rd_time.grh\",\n",
    "# \"small_world_graph_m_45_1_p_0.57_n_388970_3rd_time.grh\",\n",
    "# \"small_world_graph_m_45_2_p_0.34_n_308281_3rd_time.grh\",\n",
    "# \"small_world_graph_m_45_3_p_0.53_n_342924_3rd_time.grh\",\n",
    "# \"small_world_graph_m_45_4_p_0.48_n_253420_3rd_time.grh\",\n",
    "# \"small_world_graph_m_45_5_p_0.59_n_371202_3rd_time.grh\",\n",
    "# \"scale_free_graph_m_42_1_n_338493_4th_time.grh\",\n",
    "# \"scale_free_graph_m_42_2_n_354656_4th_time.grh\",\n",
    "# \"scale_free_graph_m_42_3_n_368016_4th_time.grh\",\n",
    "# \"scale_free_graph_m_42_4_n_340713_4th_time.grh\",\n",
    "# \"scale_free_graph_m_42_5_n_404271_4th_time.grh\",\n",
    "# \"scale_free_graph_m_43_1_n_369814_4th_time.grh\",\n",
    "# \"scale_free_graph_m_43_2_n_384689_4th_time.grh\",\n",
    "# \"scale_free_graph_m_43_3_n_380241_4th_time.grh\",\n",
    "# \"scale_free_graph_m_43_4_n_408146_4th_time.grh\",\n",
    "# \"scale_free_graph_m_43_5_n_346300_4th_time.grh\",\n",
    "# \"scale_free_graph_m_44_1_n_398394_4th_time.grh\",\n",
    "# \"scale_free_graph_m_44_2_n_395061_4th_time.grh\",\n",
    "# \"scale_free_graph_m_44_3_n_341244_4th_time.grh\",\n",
    "# \"scale_free_graph_m_44_5_n_406370_4th_time.grh\",\n",
    "# \"small_world_graph_m_48_1_p_0.27_n_314028_4th_time.grh\",\n",
    "# \"small_world_graph_m_48_2_p_0.24_n_338121_4th_time.grh\",\n",
    "# \"small_world_graph_m_48_3_p_0.26_n_297516_4th_time.grh\",\n",
    "# \"small_world_graph_m_48_4_p_0.25_n_344141_4th_time.grh\",\n",
    "# \"small_world_graph_m_48_5_p_0.24_n_326653_4th_time.grh\",\n",
    "# \"small_world_graph_m_49_2_p_0.3_n_399503_4th_time.grh\",\n",
    "# \"small_world_graph_m_49_4_p_0.28_n_349826_4th_time.grh\",\n",
    "# \"small_world_graph_m_49_5_p_0.29_n_313686_4th_time.grh\",\n",
    "# \"small_world_graph_m_50_3_p_0.29_n_283249_4th_time.grh\",\n",
    "# \"small_world_graph_m_50_4_p_0.25_n_410783_4th_time.grh\",\n",
    "# \"small_world_graph_m_50_5_p_0.28_n_427316_4th_time.grh\",\n",
    "# \"scale_free_graph_m_42_1_n_309635_5th_time.grh\",\n",
    "# \"scale_free_graph_m_43_1_n_393417_5th_time.grh\",\n",
    "# \"scale_free_graph_m_44_1_n_343785_5th_time.grh\",\n",
    "# \"scale_free_graph_m_45_1_n_438981_5th_time.grh\",\n",
    "# \"scale_free_graph_m_46_1_n_343744_5th_time.grh\",\n",
    "# \"small_world_graph_m_46_1_p_0.27_n_413968_5th_time.grh\",\n",
    "# \"small_world_graph_m_47_1_p_0.28_n_409896_5th_time.grh\",\n",
    "# \"small_world_graph_m_50_1_p_0.24_n_412595_5th_time.grh\",\n",
    "\"176bit_LCC_remapped.grh\",\n",
    "\"3D_28984_Tetra_LCC_remapped.grh\",\n",
    "\"598a_LCC_remapped.grh\",\n",
    "\"CA-CondMat_cleaned_LCC_remapped.grh\",\n",
    "\"CA-HepTh_cleaned_LCC_remapped.grh\",\n",
    "\"CL-10K-1d8-L5_LCC_remapped.grh\",\n",
    "\"OHSU_LCC_remapped.grh\",\n",
    "\"as20000102_cleaned_LCC_remapped.grh\",\n",
    "\"bio-grid-fruitfly_LCC_remapped.grh\",\n",
    "\"bio-grid-human_LCC_remapped.grh\",\n",
    "\"ca-CondMat_LCC_remapped.grh\",\n",
    "\"ca-MathSciNet_LCC_remapped.grh\",\n",
    "\"cit-DBLP_LCC_remapped.grh\",\n",
    "\"com-amazon_ungraph_cleaned_LCC_remapped.grh\",\n",
    "\"email-EU_LCC_remapped.grh\",\n",
    "\"escorts_LCC_remapped.grh\",\n",
    "\"ia-dbpedia-team-bi_LCC_remapped.grh\",\n",
    "\"ia-email-EU_LCC_remapped.grh\",\n",
    "\"ia-escorts-dynamic_LCC_remapped.grh\",\n",
    "\"oregon1_010331_cleaned_LCC_remapped.grh\",\n",
    "\"oregon1_010407_cleaned_LCC_remapped.grh\",\n",
    "\"oregon1_010526_cleaned_LCC_remapped.grh\",\n",
    "\"out_dimacs10-as22july06_cleaned_LCC_remapped.grh\",\n",
    "\"out_dimacs10-cond-mat-2003_cleaned_LCC_remapped.grh\",\n",
    "\"out_douban_cleaned_LCC_remapped.grh\",\n",
    "\"out_petster-hamster_cleaned_LCC_remapped.grh\",\n",
    "\"out_sociopatterns-infectious_cleaned_LCC_remapped.grh\",\n",
    "\"soc-political-retweet_LCC_remapped.grh\",\n",
    "\"DD_LCC_remapped.grh\",\n",
    "\"SW-10000-6-0d3-L5_LCC_remapped.grh\",\n",
    "\"cleaned_144_LCC_remapped.grh\",\n",
    "\"cleaned_auto_LCC_remapped.grh\",\n",
    "\"cleaned_bio-dmela_LCC_remapped.grh\",\n",
    "\"cleaned_citationCiteseer_LCC_remapped.grh\",\n",
    "\"cleaned_m14b_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_15_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_16_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_17_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_18_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_19_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_20_s0_LCC_remapped.grh\",\n",
    "\"cleaned_rgg_n_2_21_s0_LCC_remapped.grh\",\n",
    "\"cleaned_tech-caidaRouterLevel_LCC_remapped.grh\",\n",
    "\"cleaned_venturiLevel3_LCC_remapped.grh\",\n",
    "\"cop20k_A_LCC_remapped.grh\",\n",
    "\"out_cleaned_edit-itwikinews_LCC_remapped.grh\",\n",
    "\"out_dimacs10-cond-mat-2005_cleaned_LCC_remapped.grh\",\n",
    "\"roadNet-CA_cleaned_LCC_remapped.grh\",\n",
    "\"roadNet-PA_cleaned_LCC_remapped.grh\",\n",
    "\"roadNet-TX_cleaned_LCC_remapped.grh\",\n",
    "\"as19971108_remapped.grh\",\n",
    "\"as19991006_remapped.grh\",\n",
    "\"as19991007_remapped.grh\",\n",
    "\"as19991008_remapped.grh\",\n",
    "\"as19991009_remapped.grh\",\n",
    "\"as19991010_remapped.grh\",\n",
    "\"as19991011_remapped.grh\",\n",
    "\"as19991013_remapped.grh\",\n",
    "\"as19991016_remapped.grh\",\n",
    "\"as19991017_remapped.grh\",\n",
    "\"as19991018_remapped.grh\",\n",
    "\"as19991019_remapped.grh\",\n",
    "\"as19991026_remapped.grh\",\n",
    "\"as19991027_remapped.grh\",\n",
    "\"as19991028_remapped.grh\",\n",
    "\"as19991031_remapped.grh\",\n",
    "\"as19991105_remapped.grh\",\n",
    "\"as19991108_remapped.grh\",\n",
    "\"as19991111_remapped.grh\",\n",
    "\"as19991113_remapped.grh\",\n",
    "\"as19991114_remapped.grh\",\n",
    "\"as19991115_remapped.grh\",\n",
    "\"as19991116_remapped.grh\",\n",
    "\"as19991118_remapped.grh\",\n",
    "\"as19991121_remapped.grh\",\n",
    "\"as19991122_remapped.grh\",\n",
    "\"as19991204_remapped.grh\",\n",
    "\"as19991205_remapped.grh\",\n",
    "\"as19991206_remapped.grh\",\n",
    "\"as20000102_remapped.grh\",\n",
    "# \"selfmade_k_core.grh\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42229d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def load_grh_pce(filepath, one_indexed=True):\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         for u, line in enumerate(f):\n",
    "#             parts = line.strip().split()\n",
    "#             if not parts:\n",
    "#                 continue\n",
    "#             u_idx = u + 1 if one_indexed else u \n",
    "#             for v_str in parts:\n",
    "#                 v = int(v_str)\n",
    "#                 if one_indexed:\n",
    "#                     v -= 1  \n",
    "#                 if u_idx != v:\n",
    "#                     if u_idx < v:\n",
    "#                         G.add_edge(u_idx, v)\n",
    "#     return G\n",
    "\n",
    "# def compute_graph_stats(graph_folder, graph_files):\n",
    "#     results = []\n",
    "#     for filename in graph_files:\n",
    "#         path = os.path.join(graph_folder, filename)\n",
    "#         G = load_grh_pce(path, one_indexed=True)\n",
    "#         n_nodes = G.number_of_nodes()\n",
    "#         n_edges = G.number_of_edges()\n",
    "#         density = nx.density(G)\n",
    "#         degrees = dict(G.degree())\n",
    "#         avg_degree = sum(degrees.values()) / n_nodes if n_nodes else 0\n",
    "#         max_degree = max(degrees.values()) if degrees else 0\n",
    "#         results.append({\n",
    "#             \"Graph\": filename,\n",
    "#             \"Nodes\": n_nodes,\n",
    "#             \"Edges\": n_edges,\n",
    "#             \"Density\": round(density,6),\n",
    "#             \"Average_Degree\": round(avg_degree,6),\n",
    "#             \"Max_Degree\": max_degree\n",
    "#         })\n",
    "#     return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c118f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # ------------------- Graph Reader -------------------\n",
    "# def load_graph(filepath):\n",
    "#     \"\"\"\n",
    "#     Load a .grh adjacency list graph file into a NetworkX Graph.\n",
    "#     Each line i corresponds to node i, containing adjacent node numbers.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(filepath):\n",
    "#         raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    \n",
    "#     G = nx.Graph()\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         for u, line in enumerate(f):\n",
    "#             G.add_node(u)  # ensure node exists\n",
    "#             parts = line.strip().split()\n",
    "#             for v_str in parts:\n",
    "#                 v = int(v_str)\n",
    "#                 if u < v:  # only add edge once, avoids duplicates\n",
    "#                     G.add_edge(u, v)\n",
    "#     return G\n",
    "\n",
    "# # ------------------- Process Single File -------------------\n",
    "# def process_file(filename):\n",
    "#     file_path = os.path.join(graph_folder, filename)\n",
    "#     print(f\"Processing: {filename}\")\n",
    "\n",
    "#     try:\n",
    "#         G = load_graph(file_path)\n",
    "#         n_nodes = G.number_of_nodes()\n",
    "#         n_edges = G.number_of_edges()\n",
    "#         density = nx.density(G)\n",
    "#         degrees = dict(G.degree())\n",
    "#         avg_degree = sum(degrees.values()) / n_nodes if n_nodes > 0 else 0\n",
    "#         max_degree = max(degrees.values()) if degrees else 0\n",
    "\n",
    "#         return {\n",
    "#             \"Graph_File\": filename,\n",
    "#             \"Nodes\": n_nodes,\n",
    "#             \"Edges\": n_edges,\n",
    "#             \"Density\": round(density, 6),\n",
    "#             \"Average_Degree\": round(avg_degree, 6),\n",
    "#             \"Max_Degree\": max_degree\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         return {\n",
    "#             \"Graph_File\": filename,\n",
    "#             \"Nodes\": \"\",\n",
    "#             \"Edges\": \"\",\n",
    "#             \"Density\": \"\",\n",
    "#             \"Average_Degree\": \"\",\n",
    "#             \"Max_Degree\": \"\",\n",
    "#             \"Error\": str(e)\n",
    "#         }\n",
    "\n",
    "# # ------------------- Compute Graph Stats (Multicore) -------------------\n",
    "# def compute_graph_stats(graph_folder, graph_files, n_cpus=8):\n",
    "#     with Pool(processes=n_cpus) as pool:\n",
    "#         results = pool.map(process_file, graph_files)\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# # ------------------- Usage -------------------\n",
    "# df = compute_graph_stats(graph_folder, graph_files, n_cpus=8)\n",
    "# output_file = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491_graph_stats_real_graph.csv\")\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"\\n✅ Graph statistics saved to: {output_file}\")\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e07d7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New\n",
    "# import os\n",
    "# import re\n",
    "# import networkx as nx\n",
    "# import pandas as pd\n",
    "# from collections import Counter\n",
    "\n",
    "# INT_RE = re.compile(r\"-?\\d+\")\n",
    "\n",
    "# def detect_indexing_and_linecount(filepath):\n",
    "#     \"\"\"\n",
    "#     Return (n_lines, max_id_seen).\n",
    "#     \"\"\"\n",
    "#     n_lines = 0\n",
    "#     max_id = -1\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             n_lines += 1\n",
    "#             for m in INT_RE.findall(line):\n",
    "#                 try:\n",
    "#                     v = int(m)\n",
    "#                     if v > max_id:\n",
    "#                         max_id = v\n",
    "#                 except ValueError:\n",
    "#                     continue\n",
    "#     return n_lines, max_id\n",
    "\n",
    "# def load_graph_edge_set(filepath):\n",
    "#     \"\"\"\n",
    "#     Read .grh adjacency list into:\n",
    "#       - nodes_count = number of lines (each line corresponds to one node index)\n",
    "#       - edge_set = set of (u,v) where u < v and u,v are 0-based node indices\n",
    "#     This function auto-detects whether the file is 0-based or 1-based and\n",
    "#     maps node IDs accordingly.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(filepath):\n",
    "#         raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "\n",
    "#     # first pass: detect lines and max ID\n",
    "#     n_lines, max_id = detect_indexing_and_linecount(filepath)\n",
    "\n",
    "#     # Determine offset: if max_id == n_lines -> likely 1-based (IDs 1..n_lines)\n",
    "#     # if max_id == n_lines - 1 -> likely 0-based (IDs 0..n_lines-1)\n",
    "#     # fallback: if max_id > n_lines assume 1-based and maybe node numbering includes higher IDs\n",
    "#     if max_id == n_lines:\n",
    "#         offset = 1\n",
    "#     elif max_id == n_lines - 1:\n",
    "#         offset = 0\n",
    "#     elif max_id > n_lines:\n",
    "#         # weird but safest: assume 1-based if max_id > n_lines\n",
    "#         offset = 1\n",
    "#     else:\n",
    "#         # default to 0-based\n",
    "#         offset = 0\n",
    "\n",
    "#     edge_set = set()\n",
    "#     # We'll also count nodes as the number of lines (each line = node index)\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         for u, line in enumerate(f):\n",
    "#             # each line corresponds to node u (0-based in our representation)\n",
    "#             # parse integers from line\n",
    "#             for tok in INT_RE.findall(line):\n",
    "#                 try:\n",
    "#                     v_raw = int(tok)\n",
    "#                 except ValueError:\n",
    "#                     continue\n",
    "#                 v = v_raw - offset\n",
    "#                 # skip self-loops\n",
    "#                 if v == u:\n",
    "#                     continue\n",
    "#                 # validate v is in range [0, n_lines-1]\n",
    "#                 if v < 0 or v >= n_lines:\n",
    "#                     # ignore out-of-range neighbor (could be due to odd formatting)\n",
    "#                     continue\n",
    "#                 a, b = (u, v) if u < v else (v, u)\n",
    "#                 edge_set.add((a, b))\n",
    "\n",
    "#     return n_lines, edge_set\n",
    "\n",
    "# def compute_graph_stats(graph_folder, graph_files):\n",
    "#     results = []\n",
    "#     for filename in graph_files:\n",
    "#         file_path = os.path.join(graph_folder, filename)\n",
    "#         print(f\"Processing: {filename}\")\n",
    "\n",
    "#         try:\n",
    "#             n_nodes, edge_set = load_graph_edge_set(file_path)\n",
    "#             n_edges = len(edge_set)\n",
    "#             # density for undirected simple graph: 2*m / (n*(n-1))\n",
    "#             density = (2.0 * n_edges) / (n_nodes * (n_nodes - 1)) if n_nodes > 1 else 0.0\n",
    "\n",
    "#             # compute degrees from edge_set\n",
    "#             deg_counter = Counter()\n",
    "#             for a, b in edge_set:\n",
    "#                 deg_counter[a] += 1\n",
    "#                 deg_counter[b] += 1\n",
    "\n",
    "#             # ensure nodes with zero degree are present in degrees\n",
    "#             for node in range(n_nodes):\n",
    "#                 if node not in deg_counter:\n",
    "#                     deg_counter[node] = 0\n",
    "\n",
    "#             degrees_list = list(deg_counter.values())\n",
    "#             avg_degree = sum(degrees_list) / n_nodes if n_nodes > 0 else 0\n",
    "#             max_degree = max(degrees_list) if degrees_list else 0\n",
    "\n",
    "#             results.append({\n",
    "#                 \"Graph_File\": filename,\n",
    "#                 \"Nodes\": n_nodes,\n",
    "#                 \"Edges\": n_edges,\n",
    "#                 \"Density\": round(density, 6),\n",
    "#                 \"Average_Degree\": round(avg_degree, 6),\n",
    "#                 \"Max_Degree\": int(max_degree)\n",
    "#             })\n",
    "\n",
    "#         except Exception as e:\n",
    "#             results.append({\n",
    "#                 \"Graph_File\": filename,\n",
    "#                 \"Nodes\": \"\",\n",
    "#                 \"Edges\": \"\",\n",
    "#                 \"Density\": \"\",\n",
    "#                 \"Average_Degree\": \"\",\n",
    "#                 \"Max_Degree\": \"\",\n",
    "#                 \"Error\": str(e)\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da35f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import re\n",
    "\n",
    "# def load_grh_file(filepath, values_one_indexed=True):\n",
    "#     \"\"\"\n",
    "#     Load a PCE .grh file (after transnum.pl + transgrh.pl) into NetworkX Graph.\n",
    "#     \"\"\"\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     n_nodes = len(lines)\n",
    "\n",
    "#     # Add all nodes first (even if line is empty)\n",
    "#     for u in range(n_nodes):\n",
    "#         G.add_node(u)\n",
    "\n",
    "#     for u, line in enumerate(lines):\n",
    "#         line = line.strip()\n",
    "#         if not line:\n",
    "#             continue  # empty line -> node exists but no edges to higher-index nodes\n",
    "#         # extract integers (supports any separator)\n",
    "#         neighbors = [int(x) for x in re.findall(r'\\d+', line)]\n",
    "#         for v in neighbors:\n",
    "#             if values_one_indexed:\n",
    "#                 v -= 1  # adjust 1-based numbering\n",
    "#             if u != v:\n",
    "#                 G.add_edge(u, v)\n",
    "\n",
    "#     return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8346f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_grh_pce(filepath, values_one_indexed=True):\n",
    "\n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "    \n",
    "#     if lines and lines[0].strip() == \"\":\n",
    "#         lines = lines[1:]\n",
    "        \n",
    "#     G = nx.Graph()\n",
    "#     n_nodes = len(lines)\n",
    "\n",
    "#     # Add all nodes first\n",
    "#     for u in range(n_nodes):\n",
    "#         G.add_node(u)\n",
    "\n",
    "#     for u, line in enumerate(lines):\n",
    "#         line = line.strip()\n",
    "#         if not line:\n",
    "#             continue  # empty line -> node exists but no edges to higher-index nodes\n",
    "#         neighbors = [int(x) for x in re.findall(r'\\d+', line)]\n",
    "#         for v in neighbors:\n",
    "#             if values_one_indexed:\n",
    "#                 v -= 1  # convert 1-based to 0-based\n",
    "#             if u != v:\n",
    "#                 G.add_edge(u, v)\n",
    "\n",
    "#     return G\n",
    "\n",
    "def load_grh(filepath):\n",
    "    \"\"\"Load a .grh PCE graph into NetworkX\"\"\"\n",
    "    G = nx.Graph()\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    n_nodes = len(lines)\n",
    "    for u in range(n_nodes):\n",
    "        G.add_node(u)\n",
    "\n",
    "    for u, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        neighbors = [int(x) for x in re.findall(r'\\d+', line)]\n",
    "        for v in neighbors:\n",
    "            G.add_edge(u, v)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    return G\n",
    "\n",
    "# def load_grh_pce(filepath):\n",
    "#     \"\"\"\n",
    "#     Load a PCE-style .grh file produced by transnum + transgrh.\n",
    "#     Nodes are 1-based in file.\n",
    "#     NetworkX nodes will be 0-based.\n",
    "#     \"\"\"\n",
    "#     G = nx.Graph()\n",
    "    \n",
    "#     with open(filepath, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "    \n",
    "#     n_nodes = len(lines)\n",
    "#     for u in range(n_nodes):\n",
    "#         G.add_node(u)\n",
    "    \n",
    "#     for u, line in enumerate(lines):\n",
    "#         line = line.strip()\n",
    "#         if not line:\n",
    "#             continue\n",
    "#         # neighbors are 1-based, convert to 0-based\n",
    "#         neighbors = [int(x)-1 for x in re.findall(r'\\d+', line)]\n",
    "#         for v in neighbors:\n",
    "#             # Skip self-loops\n",
    "#             if v == u:\n",
    "#                 continue\n",
    "#             G.add_edge(u, v)\n",
    "    \n",
    "#     return G\n",
    "\n",
    "\n",
    "\n",
    "def compute_graph_stats(graph_folder, graph_files):\n",
    "    results = []\n",
    "\n",
    "    for filename in graph_files:\n",
    "        path = os.path.join(graph_folder, filename)\n",
    "        print(f\"Processing: {filename}\")\n",
    "        try:\n",
    "            G = load_grh(path)\n",
    "            G.remove_edges_from(nx.selfloop_edges(G))\n",
    "            n_nodes = G.number_of_nodes()\n",
    "            n_edges = G.number_of_edges()\n",
    "            density = nx.density(G)\n",
    "            degrees = dict(G.degree())\n",
    "#             std_degree = np.std(list(degrees.values()))\n",
    "            avg_degree = sum(degrees.values()) / n_nodes if n_nodes else 0\n",
    "            max_degree = max(degrees.values()) if degrees else 0\n",
    "            n_cores = nx.core_number(G)\n",
    "#             print(max(n_cores.values()))\n",
    "#             print(degrees)\n",
    "#             for node, deg in degrees.items():\n",
    "#                 print(f\"node-{node}: {pow(deg-avg_degree,2)}\")\n",
    "            results.append({\n",
    "                \"Graph\": filename,\n",
    "                \"Nodes\": n_nodes,\n",
    "                \"Edges\": n_edges,\n",
    "                \"Density\": round(density, 6),\n",
    "                \"Max_Degree\": max_degree,\n",
    "                \"Average_Degree\": round(avg_degree, 6),\n",
    "                \"degeneracy\":max(n_cores.values()),\n",
    "#                 \"std_degree\" : std_degree\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Graph\": filename,\n",
    "                \"Nodes\": \"\",\n",
    "                \"Edges\": \"\",\n",
    "                \"Density\": \"\",\n",
    "                \"Max_Degree\": \"\",\n",
    "                \"Average_Degree\": \"\",\n",
    "                \"degeneracy\":\"\",\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20d4002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = compute_graph_stats(graph_folder, graph_files)\n",
    "output_file = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491_06-11-26_graph_stats_selfmade_k_core.csv\")\n",
    "\n",
    "# ============================================\n",
    "# RUN & SAVE CSV\n",
    "# ============================================\n",
    "df = compute_graph_stats(graph_folder, graph_files)\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Graph statistics saved to: {output_file}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88570170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_std_deg(graph_folder, filenames):\n",
    "    results = []\n",
    "    i=1\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(graph_folder, filename)\n",
    "        print(f\"{i} Processing: {filename}\")\n",
    "        try:\n",
    "            G = load_grh(path)\n",
    "            degrees = dict(G.degree())\n",
    "            std_degree = np.std(list(degrees.values()))\n",
    "#             print(max(n_cores.values()))\n",
    "#             print(degrees)\n",
    "#             for node, deg in degrees.items():\n",
    "#                 print(f\"node-{node}: {pow(deg-avg_degree,2)}\")\n",
    "#             print(std_degree)\n",
    "            results.append({\n",
    "                \"Graph\": filename,\n",
    "                \"std_degree\" : std_degree\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Graph\": filename,\n",
    "                \"std_degree\":\"\",\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "        i = i+1\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31166134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Processing: 176bit_LCC_remapped.grh\n",
      "2 Processing: 3D_28984_Tetra_LCC_remapped.grh\n",
      "3 Processing: 598a_LCC_remapped.grh\n",
      "4 Processing: CA-CondMat_cleaned_LCC_remapped.grh\n",
      "5 Processing: CA-HepTh_cleaned_LCC_remapped.grh\n",
      "6 Processing: CL-10K-1d8-L5_LCC_remapped.grh\n",
      "7 Processing: OHSU_LCC_remapped.grh\n",
      "8 Processing: as20000102_cleaned_LCC_remapped.grh\n",
      "9 Processing: bio-grid-fruitfly_LCC_remapped.grh\n",
      "10 Processing: bio-grid-human_LCC_remapped.grh\n",
      "11 Processing: ca-CondMat_LCC_remapped.grh\n",
      "12 Processing: ca-MathSciNet_LCC_remapped.grh\n",
      "13 Processing: cit-DBLP_LCC_remapped.grh\n",
      "14 Processing: com-amazon_ungraph_cleaned_LCC_remapped.grh\n",
      "15 Processing: email-EU_LCC_remapped.grh\n",
      "16 Processing: escorts_LCC_remapped.grh\n",
      "17 Processing: ia-dbpedia-team-bi_LCC_remapped.grh\n",
      "18 Processing: ia-email-EU_LCC_remapped.grh\n",
      "19 Processing: ia-escorts-dynamic_LCC_remapped.grh\n",
      "20 Processing: oregon1_010331_cleaned_LCC_remapped.grh\n",
      "21 Processing: oregon1_010407_cleaned_LCC_remapped.grh\n",
      "22 Processing: oregon1_010526_cleaned_LCC_remapped.grh\n",
      "23 Processing: out_dimacs10-as22july06_cleaned_LCC_remapped.grh\n",
      "24 Processing: out_dimacs10-cond-mat-2003_cleaned_LCC_remapped.grh\n",
      "25 Processing: out_douban_cleaned_LCC_remapped.grh\n",
      "26 Processing: out_petster-hamster_cleaned_LCC_remapped.grh\n",
      "27 Processing: out_sociopatterns-infectious_cleaned_LCC_remapped.grh\n",
      "28 Processing: soc-political-retweet_LCC_remapped.grh\n",
      "29 Processing: DD_LCC_remapped.grh\n",
      "30 Processing: SW-10000-6-0d3-L5_LCC_remapped.grh\n",
      "31 Processing: cleaned_144_LCC_remapped.grh\n",
      "32 Processing: cleaned_auto_LCC_remapped.grh\n",
      "33 Processing: cleaned_bio-dmela_LCC_remapped.grh\n",
      "34 Processing: cleaned_citationCiteseer_LCC_remapped.grh\n",
      "35 Processing: cleaned_m14b_LCC_remapped.grh\n",
      "36 Processing: cleaned_rgg_n_2_15_s0_LCC_remapped.grh\n",
      "37 Processing: cleaned_rgg_n_2_16_s0_LCC_remapped.grh\n",
      "38 Processing: cleaned_rgg_n_2_17_s0_LCC_remapped.grh\n",
      "39 Processing: cleaned_rgg_n_2_18_s0_LCC_remapped.grh\n",
      "40 Processing: cleaned_rgg_n_2_19_s0_LCC_remapped.grh\n",
      "41 Processing: cleaned_rgg_n_2_20_s0_LCC_remapped.grh\n",
      "42 Processing: cleaned_rgg_n_2_21_s0_LCC_remapped.grh\n",
      "43 Processing: cleaned_tech-caidaRouterLevel_LCC_remapped.grh\n",
      "44 Processing: cleaned_venturiLevel3_LCC_remapped.grh\n",
      "45 Processing: cop20k_A_LCC_remapped.grh\n",
      "46 Processing: out_cleaned_edit-itwikinews_LCC_remapped.grh\n",
      "47 Processing: out_dimacs10-cond-mat-2005_cleaned_LCC_remapped.grh\n",
      "48 Processing: roadNet-CA_cleaned_LCC_remapped.grh\n",
      "49 Processing: roadNet-PA_cleaned_LCC_remapped.grh\n",
      "50 Processing: roadNet-TX_cleaned_LCC_remapped.grh\n",
      "51 Processing: as19971108_remapped.grh\n",
      "52 Processing: as19991006_remapped.grh\n",
      "53 Processing: as19991007_remapped.grh\n",
      "54 Processing: as19991008_remapped.grh\n",
      "55 Processing: as19991009_remapped.grh\n",
      "56 Processing: as19991010_remapped.grh\n",
      "57 Processing: as19991011_remapped.grh\n",
      "58 Processing: as19991013_remapped.grh\n",
      "59 Processing: as19991016_remapped.grh\n",
      "60 Processing: as19991017_remapped.grh\n",
      "61 Processing: as19991018_remapped.grh\n",
      "62 Processing: as19991019_remapped.grh\n",
      "63 Processing: as19991026_remapped.grh\n",
      "64 Processing: as19991027_remapped.grh\n",
      "65 Processing: as19991028_remapped.grh\n",
      "66 Processing: as19991031_remapped.grh\n",
      "67 Processing: as19991105_remapped.grh\n",
      "68 Processing: as19991108_remapped.grh\n",
      "69 Processing: as19991111_remapped.grh\n",
      "70 Processing: as19991113_remapped.grh\n",
      "71 Processing: as19991114_remapped.grh\n",
      "72 Processing: as19991115_remapped.grh\n",
      "73 Processing: as19991116_remapped.grh\n",
      "74 Processing: as19991118_remapped.grh\n",
      "75 Processing: as19991121_remapped.grh\n",
      "76 Processing: as19991122_remapped.grh\n",
      "77 Processing: as19991204_remapped.grh\n",
      "78 Processing: as19991205_remapped.grh\n",
      "79 Processing: as19991206_remapped.grh\n",
      "80 Processing: as20000102_remapped.grh\n",
      "\n",
      "✅ Graph statistics saved to: /home/ara2/Desktop/Najifa_Arif_CSE491_11-11-26_real_std_degree.csv\n",
      "                                 Graph  std_degree\n",
      "0              176bit_LCC_remapped.grh   86.235812\n",
      "1      3D_28984_Tetra_LCC_remapped.grh   29.758904\n",
      "2                598a_LCC_remapped.grh    2.915325\n",
      "3  CA-CondMat_cleaned_LCC_remapped.grh   10.908429\n",
      "4    CA-HepTh_cleaned_LCC_remapped.grh    6.450812\n"
     ]
    }
   ],
   "source": [
    "df = compute_std_deg(graph_folder, graph_files)\n",
    "# output_file = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491_11-11-26_synth_std_degree.csv\")\n",
    "output_file = os.path.expanduser(\"~/Desktop/Najifa_Arif_CSE491_11-11-26_real_std_degree.csv\")\n",
    "# ============================================\n",
    "# RUN & SAVE CSV\n",
    "# ============================================\n",
    "# df = compute_graph_stats(graph_folder, graph_files)\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Graph statistics saved to: {output_file}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e026e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
